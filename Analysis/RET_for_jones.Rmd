---
title: "DRAFT Analysis of the GHG Emissions Implications of the Income Mix of New Development"
author: "Nathaniel Decker"
date: "8/18/2017"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning = FALSE)
rm(list=ls())
x <- c("ggmap", "sf", "tidyverse", "foreign", 'forcats', 'censusapi', 'stringr', 'viridis', 'rvest', 'ggplot2', 'knitr') # , "tmap", "rgdal", "rgeos", "maptools", "tidyr"
lapply(x, library, character.only = TRUE) # load all necessary packages
```

## Introduction

This is a project undertaken as part of the Data Science for the 21<sup>st</sup> Century (DS421) National Science Foundation Research Traineeship. Specifically, it is a "Research Experience for Trainees," a required part of the DS421 program where the trainee contributes to research "outside of their primary discipline" for 50% of a summer. This particular project builds off of work previously performed by the author, Nathaniel Decker, (Decker et al., 2017) and the research sponsor, Christopher Jones, (Jones & Kammen, 2014, 2015).

The income of households has a dramatic impact on the effect of geography on households’ greenhouse gas (GHG) footprints (C. Jones & Kammen, 2014). The actions of local governments have a profound impact on the patterns of income-mixing in the generation of housing (Glaeser, Gyourko, & Saks, 2005; Terner Center for Housing Innovation, n.d.). We know the order-of-magnitude GHG effect of the siting of new housing in California (Decker et al., 2017; C. Jones & Kammen, 2015), but we don’t know the extent to which these impacts vary by the patterns of income mixing. This is an important policy concern because the means of facilitating the development of housing for low- to moderate-income (LMI) families are very different than the means of facilitating the development of market-rate housing.

While the GHG implications of siting LMI housing are extensively debated and have a major role in the funding of LMI housing, the GHG implications of the siting of new market-rate housing have not resulted in major policy changes or new programs. The raison d'etre of the largest state source of affordable housing funding, the Affordable Housing and Sustainable Communities Program, is GHG reduction. The criteria for California awards of the largest federal source of funding for affordable housing construction, the Low Income Housing Tax Credit, have been revised to lower the GHG emissions of these subsidized households. While some state processes to plan for and promote the construction of market rate housing, such as the housing element process, do consider the GHG emissions impact of he siting of new market-rate housing, these measures are largely toothless (Dillon 2017). 

The calculation of the GHG reduction potential stratified by the cost of housing can be used to address this pressing policy issue. This calculation should help clarify the GHG emissions payoff of regulatory changes to facilitate market-rate housing generation in infill areas.

## Thought Experiment

To estimate how much the income mix of new development matters this analysis takes the form of a thought experiment. Suppose that the next five years of residential development in California follows the geographic patterns of the last five years. Suppose that the income mix of the new residents of the state roughly matches the income mix of the regions of the state they move to. Given these suppositions we consider two scenarios: 
1. **Market Rate Infill**: development of infill market-rate housing is facilitated to the point where all market-rate housing is placed in infill areas and income-restircted housing is constructed in farther-flung locations or, 
2. **Affordable Infill**: subsidies for income-resticted housing are vastly increased and all of this housing is constructed in infill areas, but no policies are put in place to facilitate the development of new market-rate units in infill areas.

The thought experiment isolates the impact of income mix by geography. It also acknolwedges that, while the affordable housing development system in California creates a system of financing that promotes the GHG-resposible siting of housing, this goal has not yet been actualized in the various systems for market-rate development. While efforts have been made to attempt to push municipalities to adjust their land use regulations to facilitate the GHG-resposible development of new housing supply (particularly the state's requirements for Regional Housing Needs Allocations (RHNA), Annual Progress Reports (APRs), and housing elements in comprehensive plans), these systems are ineffective.

## Results

```{r cofc, include=FALSE}
######################################## PUMA Table #####################################
############## Census of Construction & Geographic Pattern of New Development ###########
###### Establish Geog. Patterns of Development by Allocating Bldg Permits to PUMAS ######

# CofC reports out by places and unincorporated areas of every county. I'll need to crosswalk this to PUMAs.
read_cofc <- function(path){
  read_csv(url(path), col_names = c('survey_date','state_code','six_digit_id','county_code','census_place_code','fips_place_code','fips_mcd_code', 'pop', 'csa_code', "cbsa_code", "footnote_code", 'central_city', 'zip_code', 'region_code', 'division_code', 'number_of_months_rep', 'place_name', 'x18_bldgs', 'one_unit_units', 'x20_value', 'x21_bldgs', 'two_units_units', 'x23_value', 'x24_bldgs', 'three_and_four_units_units', 'x26_value', 'x27_bldgs', 'five_plus_units_units'), col_types="ccccccciccccccccciiiiiiiiiii_____________",skip=3)[,1:28]
}
cofc <- read_cofc('https://www2.census.gov/econ/bps/Place/West%20Region/we2011a.txt') %>% # read in CofC, join each year and clean
  rbind(read_cofc('https://www2.census.gov/econ/bps/Place/West%20Region/we2012a.txt')) %>%
  rbind(read_cofc('https://www2.census.gov/econ/bps/Place/West%20Region/we2013a.txt')) %>%
  rbind(read_cofc('https://www2.census.gov/econ/bps/Place/West%20Region/we2014a.txt')) %>%
  rbind(read_cofc('https://www2.census.gov/econ/bps/Place/West%20Region/we2015a.txt')) %>%
  dplyr::filter(state_code == "06") %>%
  select(survey_date,
         fips_place_code, 
         county_code,
         place_name,
         pop,
         one_unit_units,
         two_units_units,
         three_and_four_units_units,
         five_plus_units_units) %>%
  mutate(fips_place_code = ifelse(is.na(fips_place_code),"0",fips_place_code)) %>% # apparently FIPS conventions for unincorporated areas and whole-county places changed over time, so sometimes it's NA, sometimes it's 00000 and sometimes it's 99990.
  mutate(county_code = paste0(county_code,"00000")) %>%
  mutate(permitted_units_annual = one_unit_units + two_units_units + three_and_four_units_units + five_plus_units_units) %>%
  mutate(county_place_code = paste0("0",as.character(as.integer(county_code) + as.integer(fips_place_code) + 600000000))) %>%
  group_by(place_name) # I'm making county-place codes for whole-counties and the unincorporated areas of counties by adding the county code and then choosing either 00000 or 99990 to represent the whole or remainder of the county. At the moment I've chosen 00000 by using the min function below
five_year_totals <- summarize(cofc,permitted_units = sum(permitted_units_annual),
                              average_population = mean(pop, na.rm = TRUE),
                              county_place_code = min(county_place_code))
# Now I'll need to consolidate the small counties that are bundled up in single PUMAs
consolidator <- function(x){
  ifelse(x %in% consol_list$input, consol_list$output[match(x, consol_list$input)], x)
}
# I'll consolidate the Nevada-ish counties (Alpine, Amador, Calaveras, Inyo, Mariposa, Mono, Tuolumne) under Alpine, the Northern counties (Del Norte, Lassen, Modoc, Plumas, Siskiyou) under Del Norte, Nevada under Sierra, Yuba under Sutter, (Colusa, Glenn, Tehama & Trinity) under Tehama, Lake under Mendocino, San Benito under monterey 
consol_list <- tibble(input = c('0600500000', '0600900000', '0602700000', '0604300000', '0605100000', '0610900000', '0603500000', '0604900000', '0606300000', '0609300000', '0609100000', '0611500000', '0601100000', '0602100000', '0610500000', '0603300000', '0606900000'), output = c('0600300000', '0600300000', '0600300000', '0600300000', '0600300000', '0600300000', '0601500000', '0601500000', '0601500000', '0601500000', '0605700000', '0610100000', '0610300000', '0610300000', '0610300000', '0604500000', '0605300000'))
five_year_totals <- mutate(five_year_totals, county_place_code = consolidator(county_place_code)) %>%
  group_by(county_place_code) %>%
  summarize(permitted_units = sum(permitted_units))
namer <- function(x,cp_code,fips){
  ifelse((x == "" | is.na(x)), cp_code, paste0(x,fips))
}
# Ok, so this crosswalk shows us there's weirdness with places and counties. Some places have one name, but different FIPS for the counties they're in (e.g. Bear Valley) some places span multiple counties, but have only one FIPS (e.g. Aromas). There are only 5 places like Aromas, where one FIPs straddles multiple counties. The places with separate FIPS should be just fine, I can join them using my place_county_codes. The places like Aromas will give me a problem, because I'll be creating a new place_county code that won't match with anything but associated with a place_name that will match. This opens the possibility that a place will either be doubled or dropped. I'll need to match by place-name or place_fips. Given that there are only five problem places, maybe I can just put them in one county or another and not have a big problem. So I'll need to do two things here: consolidate the Aromas manually and then append the FIPS to the placenames to separate out the Bear Valleys
# This will mean my county totals will be very slightly off, but my state totals should be just fine.
```
```{r crosswalk_1, include= FALSE}
mo_plc_to_cnty <- read_csv("../Data/CrosswalkPlace2Countyhaus.csv", col_names=c('FIPS_state', 'placefp14', 'county', 'State_Postal_Code', 'cntyname', 'placefp', 'placenm', 'Place_Name_2014', 'Total_HUs_2010', "placefp14_to_county_alloc_factor"), skip = 1) %>%
  dplyr::filter(FIPS_state == "06")
split_fips <- drop_na(tibble(Place_Name_2014 = unique(mo_plc_to_cnty$Place_Name_2014[duplicated(mo_plc_to_cnty$placefp14)]),
                             county = c('06053','06037','06057','06003','06017',NA)))
fips_consolidator <- function(place_name, county){
  ifelse(place_name %in% split_fips$Place_Name_2014, split_fips$county[match(place_name, split_fips$Place_Name_2014)], county)
}
mo_plc_to_cnty <- read_csv("../Data/CrosswalkPlace2Countyhaus.csv", col_names=c('FIPS_state', 'placefp14', 'county', 'State_Postal_Code', 'cntyname', 'placefp', 'placenm', 'Place_Name_2014', 'Total_HUs_2010', "placefp14_to_county_alloc_factor"), skip = 1) %>%
  dplyr::filter(FIPS_state == "06") %>%
  mutate(placefp14 = str_replace(placefp14, "99999", "00000")) %>%
  mutate(county = fips_consolidator(Place_Name_2014,county)) %>%
  mutate(county_place_code = paste0(county,placefp14),
         Total_HUs_2010 = as.integer(Total_HUs_2010),
         placefp14_to_county_alloc_factor = as.double(placefp14_to_county_alloc_factor)) %>%
  mutate(county_place_code = consolidator(county_place_code)) %>% # Ok, I'll need to consolidate some whole-counties here to make the subsequent join work.
  group_by(county_place_code,placefp14) %>%
  summarize(Total_HUs_2010 = sum(Total_HUs_2010),
            Place_Name_2014 = min(Place_Name_2014)) %>%
  mutate(Place_Name_2014 = namer(Place_Name_2014, county_place_code, placefp14))
sum(mo_plc_to_cnty$Total_HUs_2010) == 13680081 # Ok, per the 2010 Census there were 13,680,081 units of housing in CA
mo_plc_to_cnty[duplicated(mo_plc_to_cnty$county_place_code),]
length(mo_plc_to_cnty$Place_Name_2014) - length(unique(mo_plc_to_cnty$Place_Name_2014))
# Ok, so at this point we have all our places coded with counties and the whole and unincorporated areas of counties that are consolidated consolidated up. Now we're ready to read-in the PUMA crosswalk and start joining
# So the problem we have here is that there are a number of place-less codes in the place -> PUMA crosswalk. These are the unincorporated areas and whole counties, but we only know that from the names of the counties. So we'll need to manually code these.
mo_plc_to_puma <- read_csv("../Data/CrosswalkPlace2PUMAhaus.csv", col_names=c('FIPS_state', 'placefp14', 'puma12', 'State_Postal_Code', 'placefp', 'placenm', 'Place_Name_2014', 'PUMA12_Name', 'Total_HUs_2010', "placefp14_to_puma12_alloc_factor"), skip = 2) %>%
  mutate(placefp14 = str_replace(placefp14, "99999", "00000")) 
unincorp_list <- tibble(puma = mo_plc_to_puma[mo_plc_to_puma$placefp14 == "00000",]$PUMA12_Name, cnty = c(1,1,1,1,3,7,7,103,13,13,13,13,13,13,13,13,13,15,17,19,19,19,19,19,19,19,23,25,29,29,29,29,29,31,45,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,39,41,41,47,47,53,53,53,55,57,59,59,59,59,59,59,59,59,59,59,59,61,61,61,65,65,65,65,65,65,65,65,65,65,65,65,65,65,67,67,67,67,67,71,71,71,71,71,71,71,71,71,71,71,71,71,71,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,77,77,77,77,79,79,81,81,81,81,81,81,83,83,83,85,85,85,85,85,85,85,85,85,85,87,87,89,95,95,95,97,97,97,99,99,99,99,101,107,107,107,111,111,111,111,111,111,113)) %>%
  mutate(county_place_code = paste0("0",(cnty*100000)+600000000))
unincorp_ider <- function(place_fip, puma_name, place_name){
  ifelse(place_fip == "00000", unincorp_list$county_place_code[match(puma_name, unincorp_list$puma)], paste0(place_name,place_fip))
}
unincorp_consolidator <- function(units, county, cp_code){
  ifelse(is.na(units), paste0(county,"00000"), cp_code)
}
mo_plc_to_puma <-  mutate(mo_plc_to_puma, Place_Name_2014 = unincorp_ider(placefp14, PUMA12_Name, Place_Name_2014)) %>%
  left_join(mo_plc_to_cnty, by = "Place_Name_2014") %>%
  mutate(county = str_sub(county_place_code, 1, 5)) %>%
  full_join(five_year_totals, by = "county_place_code") %>%
  mutate(county_place_code = unincorp_consolidator(permitted_units, county, county_place_code)) %>%
  mutate(county_place_code = consolidator(county_place_code)) %>%
  group_by(county_place_code, puma12) %>%# Now I'm going to consolidate the unincorporated areas of each county
  summarize(PUMA12_Name = max(PUMA12_Name),
            Total_HUs_2010 = sum(Total_HUs_2010.x)) %>%
  full_join(five_year_totals, by = "county_place_code")
county_place_code_HU_totals <- group_by(mo_plc_to_puma, county_place_code) %>%
  summarize(Total_HUs_2010 = sum(Total_HUs_2010, na.rm = TRUE))
# Now the adjustment factors for the incorporated places are fine, but I'll need to come up with new adjustment factors for the unincorporated areas of counties.
# The first step is to properly define the unincorporated areas of each county. To do that I'll need an isolated county identifer
factor_adjuster <- function(cpc, hu){
  hu / county_place_code_HU_totals$Total_HUs_2010[match(cpc, county_place_code_HU_totals$county_place_code)]
}
mo_plc_to_puma <- mutate(mo_plc_to_puma, placefp14_to_puma12_alloc_factor = factor_adjuster(county_place_code, Total_HUs_2010), 
                         permitted_units_adj = placefp14_to_puma12_alloc_factor * permitted_units,
                         county = str_sub(county_place_code, 1, 5))
sum(mo_plc_to_puma$Total_HUs_2010, na.rm = TRUE) == 13680081
sum(five_year_totals$permitted_units) == sum(mo_plc_to_puma$permitted_units_adj, na.rm = TRUE)
# I'll need to consolidate the counties that are entirely within PUMAs, again, but this time by county code alone as opposed to county-place codes:
consolidator_short <- function(x){
  ifelse(x %in% consol_list_short$input, consol_list_short$output[match(x, consol_list_short$input)], x)
}
consol_list_short <- consol_list %>% map(function(x) str_sub(x, 1, 5)) %>% as.tibble # I'll need to adjust the list of county-place codes for unincorporated areas of small counties down to county codes for this dataset
puma_table <-  mutate(mo_plc_to_puma, county = consolidator_short(county)) %>%
  group_by(puma12, county) %>% # I need to be careful here because some PUMAs go across multiple counties when they're created as aaggregates of places. I'll need to consolidate here.
  summarize(Total_HUs_2010 = sum(Total_HUs_2010, na.rm = TRUE),
            permitted_units = sum(permitted_units_adj, na.rm = TRUE))
puma_table[duplicated(puma_table$puma12, fromLast = TRUE) | duplicated(puma_table$puma12, fromLast = FALSE),]
# So this shows us that two pumas _barely_ touch adjacent counties
# We're going to take those tiny exclaves and put them in the mainland
puma_table <- puma_table %>% mutate(county = ifelse(puma12 == '05908', '06059', ifelse(puma12 == '06103', '06061', county))) %>%
  group_by(puma12, county) %>% 
  summarize(Total_HUs_2010 = sum(Total_HUs_2010, na.rm = TRUE),
            permitted_units = sum(permitted_units, na.rm = TRUE))
# Now we consolidate permitted units down to PUMAs, or maybe we have to associate mfis because we still have counties here.
sum(puma_table$Total_HUs_2010, na.rm = TRUE) == 13680081
sum(five_year_totals$permitted_units) == sum(puma_table$permitted_units, na.rm = TRUE)
```
```{r census_pulls, include=FALSE}
# Now I'll add population density to the PUMA attributes by pulling in population from the Census API and pulling in land area from the shapefile
# apis <- listCensusApis()
# View(apis) # https://api.census.gov/data/2015/acs5
# vars2015 <- listCensusMetadata(name="acs5", vintage=2015, "v")
# View(vars2015)
# geos2015 <- listCensusMetadata(name="acs5", vintage=2015, "g")
# View(geos2015)
censuskey <- 'f8b8ef413394e43d536ae3829d873bf0c246b1ba'
pop2015 <- getCensus(name="acs5", 
                     vintage=2015,
                     key=censuskey, 
                     vars=c("NAME", "B01001_001E"), 
                     region="public use microdata area",
                     regionin="state:06")
puma_table <- left_join(ungroup(puma_table), pop2015, by = c('puma12' = 'public.use.microdata.area')) %>%
  transmute(puma12 = puma12,
            county = county,
            Total_HUs_2010 = Total_HUs_2010,
            permitted_units = permitted_units,
            population = B01001_001E)

# Now I'll add land area from the shapefiles
# countyshape <- readOGR(dsn = "../Data/Shapefiles", layer = "california_county_clipped_58")
countyshape <- st_read(dsn = "../Data/Shapefiles/california_county_clipped_58.shp")
# nc <- st_read(system.file("shape/nc.shp", package="sf"), quiet = TRUE)
url <- "https://www2.census.gov/geo/tiger/GENZ2016/shp/cb_2016_06_puma10_500k.zip"
downloaddir <- "../Data/Shapefiles"
destname <- "puma.zip"
download.file(url, destname)
unzip(destname, exdir=downloaddir, junkpaths=TRUE)
# pumashape <- readOGR(dsn = "../Data/Shapefiles", layer = "cb_2016_06_puma10_500k")
#library(rgdal)
#library(rgeos)
#puma_centroids <- readOGR(dsn = "../Data/Shapefiles", layer = "cb_2016_06_puma10_500k") %>%
#  gCentroid(byid=TRUE) %>%
#  st_as_sf() %>%
#  cbind(pumashape$PUMACE10)
# https://cran.r-project.org/web/packages/sf/vignettes/sf1.html
pumashape_raw <- st_read(dsn = "../Data/Shapefiles/cb_2016_06_puma10_500k.shp")
pumashape_raw$ALAND10 <- as.numeric(as.character(pumashape_raw$ALAND10))
puma_table <- left_join(puma_table, pumashape_raw, by = c("puma12" = "PUMACE10")) %>%
  transmute(puma12 = puma12,
            PUMA12_Name = NAME10,
            county = county,
            Total_HUs_2010 = Total_HUs_2010,
            permitted_units = permitted_units,
            population = population,
            pop_density = population / (ALAND10 / 4046.86))
sum(puma_table$Total_HUs_2010, na.rm = TRUE) == 13680081
sum(five_year_totals$permitted_units) == sum(puma_table$permitted_units, na.rm = TRUE)

################################### HUD MFIs by County #####################################
####################### Associating HUD MFIs from Counties to PUMAS #######################

hud_mfis <- read_csv('../Data/HUDamis/CleanHUD2015mfi.csv') #col_types="cccciiiiiiii")
hud_mfis_bins <- group_by(hud_mfis,Inc_Limit) %>%
  summarize(count = n())
# This gets a little complciated because I've got multiple HUD mfis in PUMAs, so I'll weight the mfis by growth, then round. I need to ignore negative growht in this weighting process
pop_growth <- read_csv("../data/DOFpopGrowth.csv")
total_pop_growth <- sum(pop_growth$Growth_2015_2020)
county_mfi_binned <- mutate(hud_mfis, 
                            FIPSSTCO = paste0("0",as.character(6000 + County_FIPS))) %>%
  left_join(pop_growth, by = "County") %>%
  transmute(county_name = County,
            mfi = Inc_Limit,
            county = FIPSSTCO,
            pop_growth = Growth_2015_2020) %>%
  mutate(county = consolidator_short(county),
         growth_for_weight = ifelse(pop_growth < 0, NA, pop_growth))
total_pop_growth == sum(county_mfi_binned$pop_growth)
puma_inc_denoms <- group_by(county_mfi_binned, county) %>%
  summarize(total_growth = sum(growth_for_weight, na.rm = TRUE))
# Now we need to weight by growth, but because we have negative growth in some areas we need to give these a weight of 0, otherwise our weighted average gets fucked up.
# First assocaite every puma with the mfi of the county it's in
mfi_weighter <- function(growth, county){
  ifelse(growth < 0, NA, puma_inc_denoms$total_growth[match(county, puma_inc_denoms$county)])
}
county_mfi_growth <- mutate(county_mfi_binned, weight = pop_growth / mfi_weighter(pop_growth,county)) %>%
  mutate(mfi_adjusted = mfi * weight) %>%
  ungroup() %>%
  group_by(county) %>%
  summarize(mfi = round(sum(mfi_adjusted, na.rm = TRUE), -2),
            county_pop_growth = sum(pop_growth))
# This method works for everyhting except trinity county because there's no part of the colsolidated county that is growing (and Trinity isn't consolidated, it's got its own PUMA)
county_mfi_growth <- mutate(county_mfi_growth, mfi = ifelse(mfi < 59600, 59600, mfi))
sum(pop_growth$Growth_2015_2020) == sum(county_mfi_growth$county_pop_growth)
group_by(county_mfi_growth,mfi) %>% summarize(count = n())
puma_table <- left_join(puma_table, county_mfi_growth, by = 'county') %>%
  drop_na()
puma_mfi_quantiles <- quantile(puma_table$mfi, probs = seq(0, 1, (1/5)))
puma_table <-   mutate(puma_table, region = ifelse(mfi < puma_mfi_quantiles[[2]], 5,
                                                   ifelse(mfi < puma_mfi_quantiles[[3]], 4,
                                                          ifelse(mfi < puma_mfi_quantiles[[4]], 3,
                                                                 ifelse(mfi < puma_mfi_quantiles[[5]], 2, 1)))))
puma_table %>%  group_by(region) %>% summarize(pumas = n())

######################################## Region Table ###################################
############ HUD MFIs at county allocated to clusters of counties and PUMAs #############
############# HUD income limits and Dept. of Finance population projections #############

# Now come up witht the _correct_ mfis for each region
county_weighting <- left_join(county_mfi_growth, puma_table, by = 'county') %>%
  group_by(county) %>%
  summarize(county_pop_growth = max(county_pop_growth.y),
            mfi = max(mfi.x),
            region = max(region)) %>%
  mutate(growth_for_weights = ifelse(county_pop_growth < 0, NA, county_pop_growth))
regional_growth_denom <- group_by(county_weighting, region) %>%
  summarize(regional_growth_weight = sum(growth_for_weights, na.rm = TRUE))
mfi_weighter_2 <- function(region){
  regional_growth_denom$regional_growth_weight[match(region, regional_growth_denom$region)]
} # Need to come up with a weighted mfi by region.
county_weighting <- mutate(county_weighting, weighted_mfi = mfi * (growth_for_weights / mfi_weighter_2(region))) %>%
  group_by(region) %>%
  summarize(mfi_adjusted = round(sum(weighted_mfi, na.rm = TRUE), -2))
## Also need to come up with the regional population growth totals
region_table <- mutate(pop_growth, county_fips = paste0("06", county_fips),
                       county = consolidator_short(county_fips)) %>%
  left_join(puma_table, by = 'county') %>%
  select(county_fips, Growth_2015_2020, region) %>%
  distinct() %>%
  group_by(region) %>%
  summarize(pop_growth = sum(Growth_2015_2020)) %>%
  left_join(county_weighting, by = 'region')



# Now I can finally bin the households of the state, first by putting each PUMA into its region, then by binning each household

regional_share_denom <- group_by(puma_table, region) %>%
  summarize(permitted_units_regional = sum(permitted_units))
deve_weighter <- function(deve, region){
  regional_share_denom$permitted_units_regional[match(region, regional_share_denom$region)]
}
puma_table <- mutate(puma_table, regional_deve_share = permitted_units / deve_weighter(permitted_units, region))
sum(puma_table$regional_deve_share)

# put the correct regional mfis with pumas
puma_table <- left_join(puma_table, region_table, by = 'region') %>%
  transmute(puma12 = puma12,
            PUMA12_Name = PUMA12_Name,
            county = county,
            region = region,
            Total_HUs_2010 = Total_HUs_2010,
            pop_density = pop_density,
            mfi_adjusted = mfi_adjusted,
            regional_deve_share = regional_deve_share)

hh_size_adj <- tibble(hh_size = 1:20, 
                      size_factor = c(0.70, 0.80, 0.90, seq(from = 1, to = (1+(.08*(20-4))), by = .08)))
```
```{r PUMS, include=FALSE}
######### Adding ACS data ##############
# 2011-2015 ACS PUMS : PUMA00, PUMA10, ADJINC, WGTP, NP, RMSP, VACS, VEH, HINCP
x_walk_puma <- read_csv('../Data/CrosswalkPUMA002PUMA10haus.csv')
acs <- read_csv('../Data/csv_hca/ss15hca.csv', col_types= paste0("____cc___iii",paste0(rep('_',19),collapse=""),"i",paste0(rep('_',10),collapse=""),"c_i", paste0(rep('_',9),collapse=""), "i", paste0(rep('_',(209-55)),collapse=""), collapse = "")) %>%
  left_join(x_walk_puma, by = c('PUMA00' = 'puma2k')) %>% # Crosswalk all the 2000 PUMAs from 2011 to 2010 PUMAs
  mutate(afact = as.double(afact),
         WGTP_10 = WGTP * afact,
         WGTP_adj = ifelse(is.na(WGTP_10), WGTP, WGTP_10),
         puma = ifelse(PUMA10 == "-0009", puma12, PUMA10),
         HINCP_adj = HINCP * (ADJINC/1000000)) %>%
  transmute(puma = puma,
            WGTP = WGTP_adj,
            NP = NP,
            RMSP = RMSP,
            VACS = VACS,
            VEH = VEH,
            HINCP = HINCP_adj)
(sum(acs$WGTP) - 13680081) / 13680081 # So the ACS numbers are off from the factfinder numbers by 1%
hh_inc_binner <- function(mfi, hh_size, inc){
  ifelse(inc < (hh_size_adj$size_factor[match(hh_size, hh_size_adj$hh_size)] * mfi * .3), "XLI",
         ifelse(inc < (hh_size_adj$size_factor[match(hh_size, hh_size_adj$hh_size)] * mfi * .5), "VLI", ifelse(inc < (hh_size_adj$size_factor[match(hh_size, hh_size_adj$hh_size)] * mfi * .8), "SLI", "MOD2HI")))
}
hh_ami_ider <- function(mfi, hh_size, inc){
  inc / (hh_size_adj$size_factor[match(hh_size, hh_size_adj$hh_size)] * mfi)
}
acs <- left_join(acs, puma_table, by = c('puma' = 'puma12')) %>%
  filter(is.na(VACS)) %>%
  transmute(puma = puma,
            WGTP = WGTP,
            NP = NP,
            RMSP = RMSP,
            VACS = VACS,
            VEH = VEH,
            HINCP = HINCP,
            region = region,
            mfi_adjusted = mfi_adjusted,
            inc_bin = hh_inc_binner(mfi_adjusted, NP, HINCP),
            ami_level = hh_ami_ider(mfi_adjusted, NP, HINCP))
# I want a histogram of the AMIs, colored by region
# The below isn't that interesting, but the code does work.
# ggplot(acs, aes(ami_level)) +
#   geom_histogram(binwidth = 0.01)
# ggplot(acs, aes(ami_level, colour = as.factor(region))) + geom_freqpoly(aes(y=..count../sum(..count..)), binwidth = 0.05) + coord_cartesian(xlim = c(0, 2))
# 
# ggplot(data = acs) + geom_density(aes(x = ami_level, color = as.factor(region)), kernel = "gaussian", adjust = .05)  + coord_cartesian(xlim = c(0, 5))
# I'd be interesting to calculate the % of AMI for each household, then chart these distributions by region. Right now the analysis only yields pretty slight differences in distribution, but I bet you'd see some real differences if you did a proper histogram using the raw HH AMI method.
# Apparently it's not that interesting. I would have expected that the higest income parts of the state would have a bimodal distribution, but that isn't the case, at least with the regions as I've defined them.
region_table_1 <- group_by(acs, region, inc_bin) %>% 
  summarize(inc = sum(WGTP)) %>%
  ungroup() %>%
  drop_na() %>%
  spread(key = inc_bin, value = inc) %>%
  transmute(region = region,
            XLI_pct = XLI / (XLI + SLI + MOD2HI + VLI),
            VLI_pct = VLI / (XLI + SLI + MOD2HI + VLI),
            SLI_pct = SLI / (XLI + SLI + MOD2HI + VLI),
            MOD2HI_pct = MOD2HI / (XLI + SLI + MOD2HI + VLI))
region_table <- left_join(region_table,region_table_1, by = 'region')
synth_hh <- group_by(acs, puma, inc_bin) %>%
  summarize(VEH_avr = sum(WGTP * VEH) / sum(WGTP),
            NP_avr = sum(WGTP * NP) / sum(WGTP),
            RMSP_avr = sum(WGTP * RMSP) / sum(WGTP),
            HINCP_avr = sum(WGTP * HINCP) / sum(WGTP),
            counts = n())%>% # Now I need to come up with the characteristics of my synthetic households. To do this I need to come up with the weighted average characteristics of every household in each income bin.
  drop_na() %>%
  left_join(dplyr::select(puma_table, puma12, pop_density), by = c('puma' = 'puma12')) %>%
  mutate(log_pop_density = log10(pop_density),
         ln_NP_avr = log(NP_avr)) 
# Now we need to get the right coefficients for the 
jones_zips <- read_csv("../Data/bgdata-carbon-footprint-CA.csv") %>%
  transmute(ZCTA = ZCTA,
            `Total Carbon Footprint` = `Total Carbon Footprint`,
            POPDENSITY = (PEOPLE / LANDAREA) * 4046.86,
            lnHHSIZE = log(HHSIZE),
            INCOME2013 = INCOME2013,
            VEHICLES = VEHICLES,
            ROOMS = ROOMS) %>%
  drop_na() %>%
  mutate(logPOPDENSITY = log10(POPDENSITY))
ghg_lm <- lm(`Total Carbon Footprint` ~ logPOPDENSITY + lnHHSIZE + INCOME2013 + VEHICLES + ROOMS, data = jones_zips)
summary(ghg_lm)
# library('car')
# vif(ghg_lm) # It turns out that there's not much multicollinearity, which is actually a bit of a surprise
synth_hh <- mutate(synth_hh, ghg_per_hh = ghg_lm$coefficients['(Intercept)']+ (ghg_lm$coefficients['VEHICLES'] * VEH_avr) + (ghg_lm$coefficients['INCOME2013'] * HINCP_avr) + (ghg_lm$coefficients['ROOMS'] * RMSP_avr) + 
           (ghg_lm$coefficients['lnHHSIZE'] * ln_NP_avr) + (ghg_lm$coefficients['logPOPDENSITY'] * log_pop_density),
           ghg_per_person = ghg_per_hh / NP_avr) # Create the GHG footprint for every kind of synthetic household.
#synth_hh %>% ungroup() %>% 
#  group_by(puma,inc_bin) %>% mutate_each(funs = funs(z_score = scale(.), VEH_avr:ln_NP_avr))
#synth_hh_1 <- mutate_each(synth_hh, funs = funs(z_score = scale(.), VEH_avr:ln_NP_avr))
# synth_hh_1 <- mutate_each(synth_hh[3:10], funs = funs(z_score = scale(.)))
#ghg_vars <- c('VEH_avr', 'RMSP_avr', 'HINCP_avr', 'log_pop_density', 'ln_NP_avr')
#synth_hh_1 <- mutate_at(synth_hh, .cols = one_of(ghg_vars), .funs = scale(.))

# Could also do a quick plot by income, GHGe and color by income bin
# again the below works, but isn't particularly interesting
# ggplot(data = synth_hh) + geom_point(mapping = aes(x = HINCP_avr, y = ghg_per_hh, color = inc_bin))
```
```{r assemble_big_table, include = FALSE}
big_table <- left_join(synth_hh, select(puma_table, puma12, PUMA12_Name, region, regional_deve_share), by = c('puma' = 'puma12')) %>%
  left_join(region_table, by = 'region') %>%
  mutate(deve_max = (regional_deve_share * pop_growth) / NP_avr,
         region = as.factor(region))
# ggplot(data = big_table) + geom_point(mapping = aes(x = HINCP_avr, y = ghg_per_hh, color = region)) # plot synthetic HH

## You know, it'd be interesting to map the per_hh GHG emissions of HH by geography
# pumashape_f <- fortify(pumashape)
# pumashape$id <- row.names(pumashape@data)
# pumashape_f <- left_join(pumashape_f, pumashape@data, by = c('order' = 'id'))
```
```{r shape_join, include = FALSE}
pumashape_joined <- left_join(pumashape_raw, big_table, by = c('PUMACE10' = 'puma'))
# So in the absence of professional help to deal with the simultaneous equations problems, let's do this:
# 1: use the development allocation and population projections to allocate a maximum number of _people_ to a PUMA
# 2: Then use this number of people to tranlate into the number of households. For this we'll need an allocation function, this may involve order(), and it may involve a counter with a for loop. This'll be a slow way of doing things, but it should work.
# Now we'll need to allocate/apportion
```
```{r map_init, include=FALSE}
# devtools::install_github("tidyverse/ggplot2")
region_map <- ggplot(pumashape_joined) + geom_sf(aes(fill = region))
income_footprint_mapper <- function(shp, inc){
  filter(shp, inc_bin == inc) %>%
    ggplot() + geom_sf(aes(fill = ghg_per_hh)) +
    scale_fill_viridis("Per-HH GHG Footprint") +
    ggtitle(paste0("Per-HH GHG Footprint: Synthetic Households: ", inc)) +
    theme_bw()
}
for(i in c("XLI", "VLI", "SLI", "MOD2HI")){
  nam <- paste("map", i, sep = "_")
  assign(nam, income_footprint_mapper(pumashape_joined, i))
}
# map_XLI
# map_VLI
# map_SLI
# map_MOD2HI
income_footprint_la_mapper <- function(shp, inc){
  filter(shp, inc_bin == inc) %>%
  ggplot() + geom_sf(aes(fill = ghg_per_hh)) +
  scale_fill_viridis("Per-HH GHG Footprint") +
  ggtitle(paste0("Per-HH GHG Footprint, LA: Synthetic Households: ", inc)) +
  coord_sf(xlim = c(-119, -117),ylim = c(33.5, 34.5)) +
  theme_bw()
}
for(i in c("XLI", "VLI", "SLI", "MOD2HI")){
  nam <- paste("map_LA", i, sep = "_")
  assign(nam, income_footprint_la_mapper(pumashape_joined, i))
}
# map_LA_XLI
# map_LA_VLI
# map_LA_SLI
# map_LA_MOD2HI
income_footprint_sf_mapper <- function(shp, inc){
  filter(shp, inc_bin == inc) %>%
    ggplot() + geom_sf(aes(fill = ghg_per_hh)) +
    scale_fill_viridis("Per-HH GHG Footprint") +
    ggtitle(paste0("Per-HH GHG Footprint \nSan Francisco Bay Area \nSynthetic Households: ", inc)) +
    coord_sf(xlim = c(-123, -121),ylim = c(37, 38.5)) +
    theme_bw()
}
for(i in c("XLI", "VLI", "SLI", "MOD2HI")){
  nam <- paste("map_SF", i, sep = "_")
  assign(nam, income_footprint_sf_mapper(pumashape_joined, i))
}
# map_SF_XLI
# map_SF_VLI
# map_SF_SLI
# map_SF_MOD2HI
### So what does this tell us? It tells us that geographic patterns of GHG emissions are roughly, but not exactly the same for all income levels

#pumashape@data <- left_join(pumashape@data, big_table, by = c('PUMACE10' = 'puma'))
#qtm(shp = pumashape[pumashape$inc_bin == "XLI", ], fill = "ghg_per_hh", fill.palette = "Blues")
# pumashape$id <- row.names(pumashape@data)
# pumashape_f <- left_join(pumashape_f, pumashape@data, by = c('order' = ))
# map <- ggplot(countyshape_f, aes(long, lat, group = group, fill = ami)) + geom_polygon() + scale_fill_manual(values = col_list) + coord_equal() + labs(x = "Easting (m)", y = "Northing (m)", fill = "Income Categories") + ggtitle("Regions by Income") 
# map

# at the heart of this function has to be a mutate to get the allocation of units in the puma
# But it has to be done iteratively because the columns need to be ordered
# We could start by just filtering by our regions, then filtering by our income bins
# mutate(LMI_allocation = max(deve_max, remaining_pop/NP_avr))
# allocater <- function(df, region_df){
#   dplyr::arrange(df, desc(ghg_per_hh))
#   remaining_pop <- region_df$pop_growth[match(df$region, region_df$region)]
#   for(i in rows){
#     return(ifelse(lmi_allocation <= deve_max, max(deve_max, (remaining_pop / NP_avr)), lmi_allocation))
#     remaining_pop <- remaining_pop - max(deve_max, (remaining_pop / NP_avr))
#   }
# }
# 
# test1 <- filter(big_table, region == "1") %>%
#   filter(inc_bin == "XLI") %>%
#   mutate(lmi_allocation = 0) %>%
#   rowwise() %>%
#   for(i in seq(to = nrow(big_table))){
#     remaining_pop <- region_df$pop_growth[match(big_table$region, region_df$region)]
#     mutate(lmi_allocation = ifelse(lmi_allocation <= deve_max, max(deve_max, (remaining_pop / NP_avr)), lmi_allocation))
#   }
# 
# test1 <- filter(big_table, region == "1") %>%
#   filter(inc_bin == "XLI") %>%
#   mutate(lmi_allocation = 0) %>%
#   rowwise() %>%
#   for (i in seq(to = nrow(big_table))) {
#     remaining_pop <- region_df$pop_growth[match(big_table$region, region_df$region)]
#     big_table$lmi_allocation[[i]] <- max(deve_max, (remaining_pop / NP_avr))
#     remaining_pop <- remaining_pop - max(deve_max, (remaining_pop / NP_avr))
#   }
# 
# f_by_row <- function(df) {
#   res <- by_row(df, function(row) as.list(row))
#   res$.out
# }
# 
# f_rowwise <- function(df) {
#   df %>% rowwise %>% do(alloc = max(.$deve_max, (.$pop_growth / .$NP_avr)))
# }
# 
# odd <- f_rowwise(big_table)

# split_big_table <- big_table %>% split(.$region) 
# big_table_region_1 <- filter(big_table, region == "1")
```
```{r final_analysis, include=FALSE}
inc_levels <- unique(big_table$inc_bin)
n_regions <- unique(big_table$region)
puma_blanks <- rep(0, n_distinct(big_table$puma))
outputs <- tibble(puma = unique(big_table$puma), MOD2HI = puma_blanks, SLI = puma_blanks, VLI = puma_blanks, XLI = puma_blanks)
for (h in (1:length(n_regions))){
  temp_region <- big_table[big_table$region == n_regions[h],]# for each region we create a slice of the dataframe
  for (i in 1:length(inc_levels)){ # First we iterate over the income bins
    temp <- temp_region[temp_region$inc_bin == inc_levels[i],] # for each income bin we create a slice of the dataframe
    #assign(paste0('output', inc_levels[i]), vector("double", nrow(temp))) # for each income bin we create an output vector, identified by the bin name
    #assign(paste0('pumas', inc_levels[i]), vector("double", nrow(temp))) # ... and an associated PUMA indicator
    remaining_pop <- unique(region_table$pop_growth[match(temp$region, region_table$region)]) * unique(region_table[, grepl(inc_levels[i], colnames(region_table))][[1]][match(temp$region, region_table$region)])
    temp <- dplyr::arrange(temp, ghg_per_person)
    for(j in seq(to = nrow(temp))) { # So now I've got a problem in that I'm trying to call the specific objects that I've just named, I'm ok overwriting temp and remaining pop with each itreation bby I need to preserve my output vectors
      max_pop_capacity <- temp$deve_max[j] * temp$NP_avr[j]
      # hh_remaining <- remaining_pop / temp$NP_avr[j] # I've decided to just allocate population
      already_allocated <- sum(outputs[match(temp$puma[j], outputs$puma), 2:5])
      outputs[[match(temp$puma[j], outputs$puma), i + 1]] <- round(ifelse(remaining_pop > (max_pop_capacity - already_allocated), (max_pop_capacity - already_allocated), remaining_pop), 0) # So I can't use "get" here because I can't assign to an object I get
      # get(paste0('pumas', inc_levels[i]))[[j]] <- temp$puma[[j]]
      remaining_pop <- round(remaining_pop - ifelse(remaining_pop > (max_pop_capacity - already_allocated), (max_pop_capacity - already_allocated), remaining_pop), 0)
    }
  }
}
check <- region_table %>%
  mutate_at(.vars = vars(XLI_pct, VLI_pct, SLI_pct, MOD2HI_pct),
            .funs = funs(pop_growth * .))
colSums(check[,4:7])
rev(colSums(outputs[,2:5]))
colSums(check[,4:7]) - rev(colSums(outputs[,2:5]))
sum(rev(colSums(outputs[,2:5])))
# Damn good!
# Now calculate the total GHG given this allocation of new HH
outputs <- outputs %>% gather(MOD2HI, SLI, VLI, XLI, key = "inc_bin", value = "infill_mkt_rate_pop")
big_table <- left_join(big_table, outputs, by = c("puma" = "puma", "inc_bin" = "inc_bin")) %>%
  mutate(infill_mkt_rate_hh = infill_mkt_rate_pop / NP_avr,
         infill_mkt_rate_ghg = ghg_per_hh * infill_mkt_rate_hh)
infill_mkt_rate_ghg_total <-  sum(big_table$infill_mkt_rate_ghg)
## Now reverse the order of the incomes
inc_levels <- rev(unique(big_table$inc_bin))
outputs <- tibble(puma = unique(big_table$puma), XLI = puma_blanks, VLI = puma_blanks, SLI = puma_blanks, MOD2HI = puma_blanks)
for (h in (1:length(n_regions))){
  temp_region <- big_table[big_table$region == n_regions[h],]# for each region we create a slice of the dataframe
  for (i in 1:length(inc_levels)){ # First we iterate over the income bins
    temp <- temp_region[temp_region$inc_bin == inc_levels[i],] # for each income bin we create a slice of the dataframe
    #assign(paste0('output', inc_levels[i]), vector("double", nrow(temp))) # for each income bin we create an output vector, identified by the bin name
    #assign(paste0('pumas', inc_levels[i]), vector("double", nrow(temp))) # ... and an associated PUMA indicator
    remaining_pop <- unique(region_table$pop_growth[match(temp$region, region_table$region)]) * unique(region_table[, grepl(inc_levels[i], colnames(region_table))][[1]][match(temp$region, region_table$region)])
    temp <- dplyr::arrange(temp, ghg_per_person)
    for(j in seq(to = nrow(temp))) { # So now I've got a problem in that I'm trying to call the specific objects that I've just named, I'm ok overwriting temp and remaining pop with each itreation bby I need to preserve my output vectors
      max_pop_capacity <- temp$deve_max[j] * temp$NP_avr[j]
      # hh_remaining <- remaining_pop / temp$NP_avr[j] # I've decided to just allocate population
      already_allocated <- sum(outputs[match(temp$puma[j], outputs$puma), 2:5])
      outputs[[match(temp$puma[j], outputs$puma), i + 1]] <- round(ifelse(remaining_pop > (max_pop_capacity - already_allocated), (max_pop_capacity - already_allocated), remaining_pop), 0) # So I can't use "get" here because I can't assign to an object I get
      # get(paste0('pumas', inc_levels[i]))[[j]] <- temp$puma[[j]]
      remaining_pop <- round(remaining_pop - ifelse(remaining_pop > (max_pop_capacity - already_allocated), (max_pop_capacity - already_allocated), remaining_pop), 0)
    }
  }
}
colSums(check[,4:7])
colSums(outputs[,2:5])
colSums(check[,4:7]) - colSums(outputs[,2:5])
sum(colSums(outputs[,2:5]))
# Ok, still appears to work
outputs <- outputs %>% gather(MOD2HI, SLI, VLI, XLI, key = "inc_bin", value = "infill_aff_pop")
big_table <- left_join(big_table, outputs, by = c("puma" = "puma", "inc_bin" = "inc_bin")) %>%
  mutate(infill_aff_hh = infill_aff_pop / NP_avr,
         infill_aff_ghg = ghg_per_hh * infill_aff_hh)
infill_aff_ghg_total <- sum(big_table$infill_aff_ghg)
(infill_mkt_rate_ghg_total - infill_aff_ghg_total) / infill_mkt_rate_ghg_total
# Ok, so this is as expected the infill market-rate scenario generates _less_ ghg total
(sum(big_table$infill_aff_hh) - sum(big_table$infill_mkt_rate_hh)) / sum(big_table$infill_mkt_rate_hh) # So there are more households in the affordable priority development scenario.
sum(big_table$infill_aff_pop) == sum(big_table$infill_mkt_rate_pop)
####### There are _large_ variations in the number of units going into each PUMA. I should map this out with proportional symbols
# So that's my allocation of _people_
big_table %>% group_by(inc_bin) %>% summarize(GHGe_mkt = sum(infill_mkt_rate_ghg), 
                                              GHGe_aff = sum(infill_aff_ghg),
                                              avr_ghg_per_hh_mkt = weighted.mean(ghg_per_hh, infill_mkt_rate_hh),
                                              avr_ghg_per_hh_aff = weighted.mean(ghg_per_hh,infill_aff_hh),
                                              hh_tot_mkt = sum(infill_mkt_rate_hh),
                                              hh_tot_aff = sum(infill_aff_hh))
# So that's mystifying: by prioritizing infill MOD2HI development we end up with this group emitting more.
# Why could this be? It could be that we're allocating people and not households, I doubt that that matters, though
# So it's allocating properly, the average household emissions of XLI households are lower in the infill aff scenario, and this difference is big.
```
```{r fancy_maps, include = FALSE}
puma_point <- st_centroid(pumashape_raw) %>% right_join(big_table, by = c('PUMACE10' = 'puma'))
ggplot() + geom_sf(aes(fill = region), data = pumashape_joined) + 
  geom_sf(aes(size = infill_mkt_rate_hh), data = filter(puma_point, inc_bin == "XLI")) + scale_size(range = c(0, 1)) +
  ggtitle("Per-HH GHG Footprint, LA: Synthetic Households: ") +
  coord_sf(xlim = c(-119, -117),ylim = c(33.5, 34.5)) +
  theme_bw()

ggplot() + geom_sf(aes(fill = region), data = pumashape_joined) + 
  geom_sf(aes(size = infill_mkt_rate_hh), data = filter(puma_point, inc_bin == "XLI")) + scale_size(range = c(0, 6)) +
  ggtitle("XLI Households Distribution \nMarket-Rate Infill Scenario") +
  coord_sf(xlim = c(-123, -121),ylim = c(37, 38.5)) +
  theme_bw()

ggplot() + geom_sf(aes(fill = ghg_per_hh, size = 0.5), data = filter(pumashape_joined, inc_bin == "MOD2HI")) +
  geom_sf(aes(size = infill_mkt_rate_hh, color = "orange"), data = filter(puma_point, inc_bin == "MOD2HI"), pch = 1) + scale_size(range = c(0, 6)) +
  ggtitle("Moderate to High Income Households Distribution \nMarket-Rate Infill Scenario") +
  coord_sf(xlim = c(-123, -121),ylim = c(37, 38.5)) +
  theme_bw()

pumashape_regions <- pumashape_joined %>% 
  group_by(region) %>% 
  summarise(deve_max = sum(deve_max)) %>%
  mutate(region = as.integer(region))

map_eli_mkt_rte <- ggplot() + geom_sf(aes(fill = ghg_per_hh, size = 0.5), data = filter(pumashape_joined, inc_bin == "XLI")) +
  geom_sf(aes(size = infill_mkt_rate_hh, color = "orange"), data = filter(puma_point, inc_bin == "XLI"), pch = 1) + scale_size(range = c(0, 6)) +
  # geom_sf(aes(color = region), fill = NA, data = pumashape_regions) + scale_color_continuous(low = "#ff0000", high = "#32ff00") +
  ggtitle("Extremely Low Income Households Distribution \nMarket-Rate Infill Scenario") +
  coord_sf(xlim = c(-123, -121),ylim = c(37, 38.5)) +
  theme_bw()

# map_eli_mkt_rte +
#   geom_sf(aes(color = region), fill = NA, data = pumashape_regions) +
#   # ggtitle("Hollow Regions") + 
#   # scale_color_gradient(colors = rainbow(7)) +
#   scale_color_continuous(low = "#ff0000", high = "#32ff00") 

# plot
# create hollow region plot
ggplot() +
  geom_sf(aes(color = region), fill = NA, data = pumashape_regions) +
  # ggtitle("Hollow Regions") + 
  # scale_color_gradient(colors = rainbow(7)) +
  scale_color_continuous(low = "#32ff00", high = "#ff0000") +
  theme_bw()



# So I could just include an example map and call it day. The allocations appear correct.
# If I want to go nuts I could use mapview and make some nice maps with all the layers, but it'll take a while to learn this
# I think the last bit it to show why the outcome isn't the expected outcome.
# The best way of doing that is to show

# It looks like I could use the split() function to do what I need to do by region, maybe I could
# even do this do deal with the fact I'll need to iterate over my inc_bins

# So if I left join my plce_to_puma with with the mo_plc_to_cnty I can get my county_place_code associated with every place
# Then I can left join adding the five_year_totals. That nearly gives me what I want, but not quite because my whole and unincorporated counties are under-counted. So I then need to take the places that have NAs for the construction counts and consolidate them by county, I'll do this by assigning the last 5 digits of the county_place_code for all unrepoting areas "00000"

# This crosswalk is going to be an absolute bitch. My crosswalk file gives me FIPS that match the FIPS of the CofC. But the FIPS of the unincorporated areas and whole-counties change over time, so I'll need to fix that. That's not too big a problem. The bigger problem is with the crosswalk. I'll need to isolate all the places that are reported in the CofC, then consolidate all the unused places by county. That, I think, is going to be a complicated operation.

# What I need, in the end, is a crosswalk file that takes CofC places and crosswalks then to PUMAs.
# So start with the easy part: I have a lot of places that have FIPS that match the MO crosswalk, those are fine as-is
# Then I'll have a lot of unused places left over. I'll need to crosswalk this subset of places to counties which I can identify with my county_place_codes. This will require a groupby after the crosswalk of places to counties.
# and all along the way I'll need to be sure I end up with the proper number of units in each county and in the whole state.
# So what do I need to do? I need to take my place -> PUMA crosswalk file, apply 
# Then I'll allocate all remaining housing in the county to

# So this gives us 2011 to 2015 totals of permitted units and the average population over time and, just for fun, the growth rate in units per person of each place during that period.
# So wer're going to have a little trouble here because while we have a crosswalk that allocates CDPs by fips code to PUMAs, we don't currently have a file that allocates the unincorporated parts of the counties to PUMAs.
# To get around this we could aggregate all of the CDPs that aren't listed in the CofC nto their respective counties and call those the unincorporated areas.



# [Some measure of the income mix of new residents in CA along with a total number (total number matters less) - I could just use PUMS for this too and assume that new housing should be built to roughly match the income profile of the current population]

# Things to ask Jones:
# The emissions factor for electricity - is this at the state level? It appears from the supplementary methodological materials that it is https://docs.google.com/file/d/0B_og3XZlL1dbLXRoSmtaYWVFRWc/edit), but this means that this will be a constatnt for the purposes of this analysis - I guess that's possible. Is there that much variation in carbon intensity between utilities in CA?
# If I want to be slick I could use the Census API: api.census.gov/data/2015/acs5?get=NAME,B01001_001E&for=state:*&key=...
# https://www.census.gov/data/developers/data-sets/acs-5year.html

# Our scenarios will vary by which income households we'll put in each PUMA, but within regions. So each region will have an income mix that will be duplicated in our synthetic population. That synthetic population for the region will then be allocated to the PUMAs by income.
# We'll need to come with income bins too. I'd love to only have 4-person HH, but we can't do that. We'll use four bins: XLI (30% of AMI), VLI (50% of AMI), SLI (80% of AMI), and middle (120% of AMI). Everyone's exactly at each income level. Where do I get the ratios? I could make them mirror the current income mixes. I put PUMAs into regions, I put households into income bins, and I'll have my income mix. I could show this with little pie charts ona map across the state.
# Then the allocation. Each PUMA will need to be able to accomodate all 4 income groups. Then I'll create a function that says "start at the top and work your way down." 
# This means I'll also need to crosswalk counties to PUMAs
```

The California Department of Finance projects that the state will add `r prettyNum(as.integer(40719999-39059809), big.mark = ",")` new residents in `r prettyNum(as.integer(13864699-13236154), big.mark = ",")` households. This analysis assumes that the growth projected by the department of finance over the next 5 years will be accomodated with new housing construction and that this volume will roughly follow the regional patterns predicted by the department of finance. Within each region the neighborhood patterns of development will reflect the patterns of the past 5 years. (See the appendix for a description of the methods.)

In this thought experiment there is no difference in the location of new development. The same sites are developed in the same cities and suburbs. The difference comes from the buildings that are developed, and whether the buildings are income-restricted or not. In scenario 1 the 

This analysis is conservative. 

If the lowest income households are placed in the lowest HH GHG areas:
[Table that breaks out total GHGe by income bracket, summed up across the state, with a total row at the bottom]
```{r results_table, echo= FALSE, results = 'asis'}
big_table %>% ungroup() %>% group_by(inc_bin) %>% summarize(`Households: Market Infill (1,000s)` = sum(infill_mkt_rate_hh) / 1000,
                                              `Households: Affordable Infill (1,000s)` = sum(infill_aff_hh) / 1000,
                                              `Emissions: Market Infill (1,000s)` = sum(infill_mkt_rate_ghg) / 1000,
                                              `Emissions: Affordable Infill (1,000s)`  = sum(infill_aff_ghg) / 1000,
                                              `Per-HH Emissions: Market Infill` = weighted.mean(ghg_per_hh, infill_mkt_rate_hh),
                                              `Per-HH Emissions: Affordable Infill` = weighted.mean(ghg_per_hh,infill_aff_hh)) %>%
  mutate_at(.vars = vars(`Households: Market Infill (1,000s)`, `Households: Affordable Infill (1,000s)`, `Emissions: Market Infill (1,000s)`, `Emissions: Affordable Infill (1,000s)`),
            .funs = funs(round(. ,0))) %>%
  mutate_at(.vars = vars(`Per-HH Emissions: Market Infill`, `Per-HH Emissions: Affordable Infill`),
            .funs = funs(round(. ,1))) %>%
  select(`Income Category` = inc_bin, 2:7) %>%
  rbind(c("Total",as.list(unlist(t(colSums(.[,-1])))[1:4]),as.list(unlist(t(colMeans(.[,-1])))[5:6]))) %>%
  kable(format = 'markdown', format.args = list(big.mark = ','), caption = "Summary Results")
```

So it's a difference of `r ((infill_mkt_rate_ghg_total - infill_aff_ghg_total) / infill_mkt_rate_ghg_total) * 100`%. Yeah.

## Dividing the State into Regions

Our scenarios won't assume that all low income households are in SF or not. It'll break the state up into regions and allocate households within regions. DoF releases population projections at the county level so our regions will be groups of counties. We'll divide the state up using area median income levels set by HUD. 

Digital paup.

```{r present_maps, echo=FALSE}
region_map <- ggplot(pumashape_regions) + geom_sf(aes(fill = region))
income_footprint_mapper <- function(shp, inc){
  filter(shp, inc_bin == inc) %>%
    ggplot() + geom_sf(aes(fill = ghg_per_hh)) +
    scale_fill_viridis("Per-HH GHG Footprint") +
    ggtitle(paste0("Per-HH GHG Footprint: Synthetic Households: ", inc)) +
    theme_bw()
}
for(i in c("XLI", "VLI", "SLI", "MOD2HI")){
  nam <- paste("map", i, sep = "_")
  assign(nam, income_footprint_mapper(pumashape_joined, i))
}
# map_XLI
# map_VLI
# map_SLI
# map_MOD2HI
income_footprint_la_mapper <- function(shp, inc){
  filter(shp, inc_bin == inc) %>%
  ggplot() + geom_sf(aes(fill = ghg_per_hh)) +
  scale_fill_viridis("Per-HH GHG Footprint") +
  ggtitle(paste0("Per-HH GHG Footprint, LA: Synthetic Households: ", inc)) +
  coord_sf(xlim = c(-119, -117),ylim = c(33.5, 34.5)) +
  theme_bw()
}
for(i in c("XLI", "VLI", "SLI", "MOD2HI")){
  nam <- paste("map_LA", i, sep = "_")
  assign(nam, income_footprint_la_mapper(pumashape_joined, i))
}
# map_LA_XLI
# map_LA_VLI
# map_LA_SLI
# map_LA_MOD2HI
income_footprint_sf_mapper <- function(shp, inc){
  filter(shp, inc_bin == inc) %>%
    ggplot() + geom_sf(aes(fill = ghg_per_person)) +
    scale_fill_viridis("Per-HH GHG Footprint") +
    ggtitle(paste0("Per-HH GHG Footprint \nSan Francisco Bay Area \nSynthetic Households: ", inc)) +
    coord_sf(xlim = c(-123, -121),ylim = c(37, 38.5)) +
    theme_bw()
}
for(i in c("XLI", "VLI", "SLI", "MOD2HI")){
  nam <- paste("map_SF", i, sep = "_")
  assign(nam, income_footprint_sf_mapper(pumashape_joined, i))
}
map_SF_XLI
map_SF_VLI
map_SF_SLI
map_SF_MOD2HI
ggplot() + geom_sf(aes(fill = ghg_per_hh, size = 0.5), data = filter(pumashape_joined, inc_bin == "MOD2HI")) +
  geom_sf(aes(size = infill_mkt_rate_hh, color = "orange"), data = filter(puma_point, inc_bin == "MOD2HI"), pch = 1) + scale_size(range = c(0, 6)) +
  ggtitle("Moderate to High Income Households Distribution \nMarket-Rate Infill Scenario") +
  coord_sf(xlim = c(-123, -121),ylim = c(37, 38.5)) +
  theme_bw()
```

## References

California Department of Finance. (n.d.). Demographic Projections. Retrieved July 1, 2017, from http://www.dof.ca.gov/Forecasting/Demographics/Projections/

Decker, N., Galante, C., Chapple, K., Martin, A., Elkind, E. N., & Hanson, M. (2017). Right Type, Right Place: Assessing the Environmental and Economic Impacts of Infill Residential Development through 2030. Berkeley, CA: Terner Center for Housing Innovation & Center for Law, Energy and the Environment (CLEE). Retrieved from http://next10.org/right-housing

Dillon, L. (2017, June 29). California lawmakers have tried for 50 years to fix the state’s housing crisis. Here’s why they’ve failed. Los Angeles Times. Retrieved from http://www.latimes.com/projects/la-pol-ca-housing-supply/

Glaeser, E. L., Gyourko, J., & Saks, R. (2005). Why Is Manhattan So Expensive? Regulation and the Rise in Housing Prices. The Journal of Law and Economics, 48(2), 331–369. https://doi.org/10.1086/429979

Jones, C. M., & Kammen, D. M. (2014). Spatial Distribution of U.S. Household Carbon Footprints Reveals Suburbanization Undermines Greenhouse Gas Benefits of Urban Population Density. Environmental Science & Technology, 48(2), 895–902. https://doi.org/10.1021/es4034364

Jones, C. M., & Kammen, D. M. (2015). A Consumption-Based Greenhouse Gas Inventory of San Francisco Bay Area Neighborhoods, Cities and Counties: Prioritizing Climate Action for Different Locations. Bay Area Air Quality Management District. Retrieved from http://escholarship.org/uc/item/2sn7m83z

Terner Center for Housing Innovation. (n.d.). Housing Development Dashboard. Retrieved July 1, 2017, from https://ternercenter.berkeley.edu/dashboard

